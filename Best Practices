from celery.task import Task   # << OLD Task base class.

from celery import Task        # << NEW base class.
The new base class is recommended even if you use the old module-based API.

---------------------------------------------------------------------------------------------------------------------------------------
While it’s possible to depend on the current app being set, the best practice is to always pass the app instance around to anything that needs it.
 call this the “app chain”, since it creates a chain of instances depending on the app being passed.

The following example is considered bad practice:

############################################## This is bad practice
from celery import current_app

class Scheduler(object):

    def run(self):
        app = current_app
###############################################
Instead it should take the app as an argument:


########################################## Good practice
class Scheduler(object):

    def __init__(self, app):
        self.app = app
###########################################

Internally Celery uses the celery.app.app_or_default() function so that everything also works in the module-based compatibility API


######################################################## Allows module based api compatibility
from celery.app import app_or_default

class Scheduler(object):
    def __init__(self, app=None):
        self.app = app_or_default(app)
#######################################################

In development you can set the CELERY_TRACE_APP environment variable to raise an exception if the app chain breaks:

$ CELERY_TRACE_APP=1 celery worker -l info

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

A task that blocks indefinitely may eventually stop the worker instance from doing any other work.

If you task does I/O then make sure you add timeouts to these operations, like adding a timeout to a web request using the
requests library:

connect_timeout, read_timeout = 5.0, 30.0
response = requests.get(URL, timeout=(connect_timeout, read_timeout))

Time limits are convenient for making sure all tasks return in a timely manner, but a time limit event will actually kill the
process by force so only use them to detect cases where you haven’t used manual timeouts yet.

-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
The default prefork pool scheduler is not friendly to long-running tasks, so if you have tasks that run for minutes/hours make
sure you enable the -Ofair command-line argument to the celery worker.
See Prefork pool prefetch settings for more information, and for the best performance route long-running and short-running tasks
to dedicated workers (Automatic routing).

--------------------------------------------------------------------------------------------------------------------------------------------

@app.task(name='name of the task') # best practice is name = module_name.task_name
You can set this name manually, or a name will be automatically generated using the module and class name.

-------------------------------------------------------------------------------------------------------------------------------------


